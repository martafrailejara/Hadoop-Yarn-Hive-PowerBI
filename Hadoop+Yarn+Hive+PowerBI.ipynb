{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levantar un flujo analítico sencillo con estos servicios: Hadoop + YARN + Hive + PowerBI. No usar Spark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Crea un directorio para tu proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mkdir hadoop+yarn+hive+powerBI\n",
    "cd hadoop+yarn+hiv+powerBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dentro de este directorio, tienes que hacer un pull al siguiente repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "git clone https://github.com/big-data-europe/docker-hive.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Te metes dentro de la carpeta que se ha generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cd docker-hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Inicias los servicios definidos en el archivo docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Ejecuta el comando docker-compose exec hive-server bash para acceder a un shell interactivo dentro del contenedor del servidor Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose exec hive-server bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. El siguiente comando se utiliza para iniciar Beeline, que es una herramienta de línea de comandos para interactuar con Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "/opt/hive/bin/beeline -u jdbc:hive2://localhost:10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ahora se ha iniciado la consola de hive donde podemos empezar a introducir unas querys, puedes probar con las siguientes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "CREATE DATABASE test_db;\n",
    "USE test_db;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE test_table (id INT, name STRING);\n",
    "INSERT INTO TABLE test_table VALUES (1, 'Alice'), (2, 'Bob');\n",
    "SELECT * FROM test_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Descargar la version de escritorio de Power BI desde la Microsoft Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Conectarse a traves de ODBC con la cadena de conexion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ejemplo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "jdbc:hive2://localhost:10000/default;transportMode=http;httpPath=cliservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*En power BI ya podemos generar tablas y graficos con los datos que hemos introducido anteriormente*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Dockerizar el proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Crea un dockerfile e introduce esto*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FROM bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8\n",
    "COPY docker-compose.yml /app/\n",
    "WORKDIR /app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Construye la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker build -t hadoop-cluster-image ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ahora, cualquier usuario que tenga la imagen puede correr un contenedor basado en esta y ejecutar los comandos para iniciar el clúster.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
